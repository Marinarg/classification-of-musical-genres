{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Aprendizado de Máquina: Classificador Musical\n",
    "\n",
    "Marina Rocha Guimarães\n",
    "\n",
    "Ygor Kupas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos dois objetivos centrais nesse notebook:\n",
    "\n",
    "* No cenário I iremos utilizar um SVM e analisar os diferentes resultados obtidos ao utilizarmos diferentes extrações de features (LPC, MFCC e Mel Spectogram) e suas combinações (MFCC + LPC e Mel Spectogram + LPC). Isso é uma simplificação baseada no estudo realizado em [1];\n",
    "    \n",
    "* No cenário II iremos utilizar 3 SVMs, com o intuito de comparar os resultados obtidos no cenário I com o resultado obtido ao separar inicialmente os 4 estilos musicais em 2 grupos distintos (como feito em [2]).\n",
    "\n",
    "[1] [Mutiara,A.B.; Refianti,R.; Mukarromah, N. R. A. Musical Genre Classification Using Support Vector Machines and Audio Features. Faculty of Computer Science and Information Technology, Gunadarma University. Setembro, 2016](https://pdfs.semanticscholar.org/92b4/66160755cd4c540cad6ab744019ee006e4ec.pdf)\n",
    "\n",
    "[2] [XU, Changseng et al. Musical Genre Classification Using Support Vector Machines. Laboratories for Information Technology, 2003](https://www.researchgate.net/publication/4015150_Musical_genre_classification_using_support_vector_machines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indice<br/><br/>1 - [Importando Libs](#1---Importando-Libs)<br/>2 - [Apagando os avisos do notebook](#2---Apagando-os-avisos-do-notebook)<br/>3 - [Carregando Dataset](#3---Carregando-Dataset)<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.1 - [Testando os audios](#3.1---Testando-os-audios)<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2 - [Separando Treinamento e Teste](#3.2---Separando-Treinamento-e-Teste)<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.2.1 - [Verificando a distribuição de treinamento e teste entre os estilos musicais](#3.2.1---Verificando-a-distribuição-de-treinamento-e-teste-entre-os-estilos-musicais)<br/>4 - [Extração de Features](#4---Extração-de-Features)<br/>5 - [Cenário I](#5---Cenário-I)<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.1 - [Encontrando os melhores parâmetros para cada feature](#5.1---Encontrando-os-melhores-parâmetros-para-cada-feature)<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.2 - [Melhor Resultado](#5.2---Melhor-Resultado)<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.2.1 - [Tentativa de predição com o melhor modelo](#5.2.1---Tentativa-de-predição-com-o-melhor-modelo)<br/>6 - [Cenário II](#6---Cenário-II)6.1 - [Analisando cada extração de feature](#6.1---Analisando-cada-extração-de-feature)<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.2 - [Melhor Resultado](#6.2---Melhor-Resultado)<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.2.1 - [Tentativa de predição com o melhor modelo](#6.2.1---Tentativa-de-predição-com-o-melhor-modelo)<br/>7 - [Comparando os melhores resultados de cada cenário](#7---Comparando-os-melhores-resultados-de-cada-cenário)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importando Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs matplotlib, numpy and pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Lib librosa\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Lib OS\n",
    "from os import listdir\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "# Lib ipwidgets\n",
    "from ipywidgets import interact, IntSlider, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Lib IPtyhon\n",
    "from IPython import display as ipd\n",
    "\n",
    "# Lib glob\n",
    "import glob\n",
    "\n",
    "# Lib sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Lib keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "# Lib collections\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Apagando os avisos do notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings off\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Carregando Dataset\n",
    "\n",
    "Baixar todo o [dataset](https://www.kaggle.com/carlthome/gtzan-genre-collection) (genre/) e colocar na mesma pasta do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_signal(path):\n",
    "    \n",
    "    # Test if path exists\n",
    "    if( exists(path) == False ):\n",
    "        print(\"Path does not exist, download from https://www.kaggle.com/carlthome/gtzan-genre-collection\")\n",
    "        return 0, 0\n",
    "    \n",
    "    # Load files woth glob\n",
    "    files = glob.glob(path + '*.au')\n",
    "    audios = []\n",
    "    \n",
    "    # Load audio files with sample rate 22050 Hz\n",
    "    for file in files: \n",
    "        s, sr = librosa.core.load(file, sr=22050)\n",
    "        audios.append(s)\n",
    "        \n",
    "    # Return audio vector and sample rate\n",
    "    return audios, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos considerar os seguintes rótulos para cada estilo:\n",
    "\n",
    "    * Popular  =>  y=0 e y2=0\n",
    "    * Clássico =>  y=1 e y2=0\n",
    "    * Jazz     =>  y=2 e y2=1\n",
    "    * Rock     =>  y=3 e y2=1\n",
    "    \n",
    "Isso porque **y** equivale ao rótulo do **primeiro cenário**, no qual temos apenas uma SVM e 4 possíveis saídas. Já o **segundo cenário** usa tanto o **y2** (na primeira SVM) como o **y** (já que a primeira SVM é usada para separar os estilos popular e clássico dos estilos jazz e rock)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audios dataframe\n",
    "def get_audios_df():\n",
    "    \n",
    "    cont = 0\n",
    "    audios_dict = defaultdict(list)\n",
    "    \n",
    "    # Loop in music genres\n",
    "    for musical_genre in ['pop', 'classical', 'jazz', 'rock']:\n",
    "\n",
    "        # Importing signals\n",
    "        audios, sr =  import_signal(f'genres/{musical_genre}/')\n",
    "        \n",
    "        #\n",
    "        audios_dict[musical_genre].append(audios)\n",
    "        \n",
    "        # Joining all genres in one dataframe\n",
    "        audios_df_aux = pd.DataFrame([[x] for x in audios], columns=['x'])\n",
    "        genre_dict_y = {'pop':0, 'classical':1, 'jazz':2, 'rock':3}\n",
    "        genre_dict_y2 = {'pop':0, 'classical':0, 'jazz':1, 'rock':1}\n",
    "        audios_df_aux['y'] = genre_dict_y[f'{musical_genre}']\n",
    "        audios_df_aux['y2'] = genre_dict_y2[f'{musical_genre}']\n",
    "        \n",
    "        if cont == 0:\n",
    "            audios_df = audios_df_aux\n",
    "        else:\n",
    "            audios_df = pd.concat([audios_df, audios_df_aux])\n",
    "        cont+=1\n",
    "        \n",
    "    return audios_df, audios_dict, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call \"get_audio_df()\" function\n",
    "audios_df, audios_dict, sr = get_audios_df()\n",
    "\n",
    "# Shuffle all music genres\n",
    "audios_df = audios_df.sample(frac=1).reset_index(drop=True) # shuffle\n",
    "\n",
    "# Printing rows number\n",
    "print(f'Rows: {len(audios_df)}')\n",
    "audios_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Testando os audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring global variables to interact\n",
    "global chosed_musical_genre\n",
    "chosed_musical_genre = 'pop'\n",
    "global chosed_file\n",
    "chosed_file = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropdown from widgets\n",
    "w_dropdown = widgets.Dropdown(options=['pop', 'classical', 'jazz', 'rock'],\n",
    "                              value='pop', description='Genero:', disabled=False)\n",
    "\n",
    "output_dropdown = widgets.Output()\n",
    "\n",
    "# Changing \"chosed_musical_genre\"\n",
    "def on_change_dropdown(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        global chosed_musical_genre\n",
    "        chosed_musical_genre = change['new']\n",
    "        ipd.display(ipd.Javascript('IPython.notebook.execute_cells([16])'))\n",
    "\n",
    "w_dropdown.observe(on_change_dropdown)\n",
    "display(w_dropdown, output_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IntSlider from widgets\n",
    "w_int_slider = widgets.IntSlider(value=0, min=0, max=99, step=1,\n",
    "                                 description='File:', disabled=False,\n",
    "                                 continuous_update=False, orientation='horizontal',\n",
    "                                 readout=True, readout_format='d')\n",
    "\n",
    "output_int_slider = widgets.Output()\n",
    "\n",
    "# Changing \"chosed_file\"\n",
    "def on_change_int_slider(change):\n",
    "    with output_int_slider:\n",
    "        global chosed_file\n",
    "        chosed_file = change['new']\n",
    "        ipd.display(ipd.Javascript('IPython.notebook.execute_cells([16])'))\n",
    "\n",
    "w_int_slider.observe(on_change_int_slider, 'value')\n",
    "display(w_int_slider, output_int_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show audio\n",
    "ipd.Audio(audios_dict[chosed_musical_genre][0][chosed_file], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Separando Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numpy random to separate training and test data\n",
    "# Could use sklearn.model_selection.train_test_split\n",
    "\n",
    "# 80% for training and 20% for tests (approximately)\n",
    "msk = np.random.rand(len(audios_df)) < 0.8\n",
    "train = audios_df[msk]\n",
    "test = audios_df[~msk]\n",
    "\n",
    "# Showing train and test's rows\n",
    "print(f'Rows train:{len(train)}')\n",
    "print(f'Rows test:{len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 - Verificando a distribuição de treinamento e teste entre os estilos musicais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing a histogram for test and train distribution\n",
    "\n",
    "bins_y = np.sort(train['y'].unique())\n",
    "bins_y2 = np.sort(train['y2'].unique())\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15,10))\n",
    "\n",
    "axs[0, 0].bar(bins_y, np.histogram(train['y'], bins=len(bins_y))[0], \n",
    "              align='center', color='#ff66b3', ec='#ffffff')\n",
    "axs[0, 0].set_xticks(bins_y)\n",
    "axs[0, 0].set_title('Treinamento (y)', fontsize=16)\n",
    "\n",
    "axs[0, 1].bar(bins_y2, np.histogram(train['y2'], bins=len(bins_y2))[0], \n",
    "              align='center', color='#ff66b3', ec='#ffffff')\n",
    "axs[0, 1].set_xticks(bins_y2)\n",
    "axs[0, 1].set_title('Treinamento (y2)', fontsize=16)\n",
    "\n",
    "axs[1, 0].bar(bins_y, np.histogram(test['y'], bins=len(bins_y))[0], \n",
    "              align='center', color='#ff66b3', ec='#ffffff')\n",
    "axs[1, 0].set_xticks(bins_y)\n",
    "axs[1, 0].set_title('Teste (y)', fontsize=16)\n",
    "\n",
    "axs[1, 1].bar(bins_y2, np.histogram(test['y2'], bins=len(bins_y2))[0], \n",
    "              align='center', color='#ff66b3', ec='#ffffff')\n",
    "axs[1, 1].set_xticks(bins_y2)\n",
    "axs[1, 1].set_title('Teste (y2)', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Extração de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_feature_extract(x_column, sr):\n",
    "    mfcc_list = []\n",
    "    for x in x_column:\n",
    "        \n",
    "        # Transform to frequency domain with cossenoid transform\n",
    "        # .flatten() to transform an array to a single vector\n",
    "        mfcc_flatten = np.array(librosa.feature.mfcc(y=x, sr=sr)).flatten()\n",
    "        \n",
    "        # It is done becouse for each x, it has different sizes \n",
    "        # of MFCC (max is 26280)\n",
    "        zeros = np.zeros((26280 - len(mfcc_flatten))) \n",
    "                       \n",
    "        # Append in MFCC list\n",
    "        mfcc_list.append(np.concatenate((mfcc_flatten, zeros), axis=0))\n",
    "        \n",
    "    return mfcc_list\n",
    "\n",
    "def mel_spect_feature_extract(x_column, sr):\n",
    "    mel_spect_list = []\n",
    "    for x in x_column:\n",
    "        \n",
    "        # Transform to frequency domain\n",
    "        # .flatten() to transform an array to a single vector\n",
    "        mel_spect_flatten = np.array(librosa.feature.melspectrogram(y=x, sr=sr)).flatten()\n",
    "        \n",
    "        # It is done becouse for each x, it has different sizes \n",
    "        # of Mel Specs (max is 168192)\n",
    "        zeros = np.zeros((168192 - len(mel_spect_flatten))) \n",
    "                              \n",
    "        # Append in Mel_Spec list\n",
    "        mel_spect_list.append(np.concatenate((mel_spect_flatten, zeros), axis=0))\n",
    "        \n",
    "    return mel_spect_list\n",
    "\n",
    "def lpc_feature_extract(x_column, order=6):\n",
    "    lpc_list = []\n",
    "    for x in x_column:\n",
    "        # Linear \n",
    "        lpc = librosa.lpc(x, order=order)\n",
    "        lpc_list.append(lpc)\n",
    "    return lpc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all features extrations\n",
    "def feature_extract(df, sr):\n",
    "    \n",
    "    # MFCC\n",
    "    df['mfcc'] = mfcc_feature_extract(df['x'], sr)\n",
    "    \n",
    "    # LPC\n",
    "    df['lpc'] = lpc_feature_extract(df['x'], order=6)\n",
    "    \n",
    "    # Mel Spectogram\n",
    "    df['mel_spect'] = mel_spect_feature_extract(df['x'], sr)\n",
    "    \n",
    "    # MFCC + LPC\n",
    "    df['mfcc_lpc'] = (\n",
    "        df['mfcc'].apply(lambda x: x.tolist()) + \n",
    "        df['lpc'].apply(lambda x: x.tolist())\n",
    "    )\n",
    "    \n",
    "    # Mel Spectogram + LPC\n",
    "    df['mel_spect_lpc'] = (\n",
    "        df['mel_spect'].apply(lambda x: x.tolist()) + \n",
    "        df['lpc'].apply(lambda x: x.tolist())\n",
    "    )\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train extraction\n",
    "train = feature_extract(train, sr)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extraction\n",
    "test = feature_extract(test, sr)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Cenário I\n",
    "\n",
    "* Usando uma rede SVM de apenas uma cama para reconhecer os 4 tipos musicais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 - Encontrando os melhores parâmetros para cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('poly', 'rbf'), 'C':[1, 5], 'degree':[1,6], 'gamma':[0.7,1.7]}\n",
    "\n",
    "svc = svm.SVC()\n",
    "model = GridSearchCV(svc, parameters)\n",
    "\n",
    "features_params_dict = defaultdict(dict)\n",
    "\n",
    "features_without_abrev = {'mfcc':'MFCC', 'lpc':'LPC', 'mel_spect':'Mel Spectogram',\n",
    "                          'mfcc_lpc': 'MFCC + LPC', 'mel_spect_lpc': 'Mel Spectogram + LPC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in ['mfcc', 'lpc', 'mel_spect', 'mfcc_lpc', 'mel_spect_lpc']:\n",
    "        \n",
    "    print(f'\\033[1m {features_without_abrev[feature]}:\\033[0;0m\\n')\n",
    "    \n",
    "    # Training\n",
    "    model.fit(train[f'{feature}'].to_list(), train['y'].to_list())\n",
    "    \n",
    "    # Best Parameters\n",
    "    print(f'Best parameters: {model.best_params_}')\n",
    "    features_params_dict[feature] = model.best_params_\n",
    "    \n",
    "    # Train and Test Score\n",
    "    train_score = model.score(train[f'{feature}'].to_list(), train['y'].to_list())\n",
    "    test_score = model.score(test[f'{feature}'].to_list(), test['y'].to_list())\n",
    "    \n",
    "    print('\\033[1m' + 'Train accuracy:' + '\\033[0;0m' + ' {:.1%}'.format(train_score))\n",
    "    print('\\033[1m' + 'Test accuracy: '+ '\\033[0;0m' + ' {:.1%}'.format(test_score))\n",
    "    print('\\n')\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    disp = plot_confusion_matrix(model, test[f'{feature}'].to_list(), \n",
    "                                 test['y'].to_list(), labels=[0,1,2,3],\n",
    "                                 display_labels=['pop', 'classical', 'jazz', 'rock'],\n",
    "                                 cmap=plt.cm.BuPu)\n",
    "    disp.ax_.set_title(f'Confusion Matrix Using {features_without_abrev[feature]} (first scenario)', \n",
    "                       fontsize=16)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Melhor Resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando o melhor resultado com base principalmente na porcentagem de acerto no dataset de teste, temos 2 melhores modelos:\n",
    "    * SVM com kernel=poly e extração de feature MFCC\n",
    "    * SVM com kernel=poly e extração de feature MFCC+LPC\n",
    "\n",
    "Nota-se que os dois resultados acima são identicos. Vamos então escolher o primeiro citado para verificar o resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_score, test_score = (\n",
    "    get_first_scenario_score_and_model(train, test, features_params_dict, \n",
    "                                       feature='mfcc')\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "disp = plot_confusion_matrix(model, test['mfcc'].to_list(), \n",
    "                             test['y'].to_list(), labels=[0,1,2,3],\n",
    "                             display_labels=['pop', 'classical', 'jazz', 'rock'],\n",
    "                             cmap=plt.cm.BuPu)\n",
    "disp.ax_.set_title('Confusion Matrix Using MFCC (first scenario)', fontsize=16)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1m' + 'Train accuracy:' + '\\033[0;0m' + ' {:.1%}'.format(train_score))\n",
    "print('\\033[1m' + 'Test accuracy: '+ '\\033[0;0m' + ' {:.1%}'.format(test_score))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 - Tentativa de predição com o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global chosed_musical_genre_scenario1\n",
    "chosed_musical_genre_scenario1 = 'pop'\n",
    "\n",
    "global chosed_file_scenario1\n",
    "chosed_file_scenario1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dropdown = widgets.Dropdown(options=['pop', 'classical', 'jazz', 'rock'],\n",
    "                              value='pop', description='Genero:', disabled=False)\n",
    "\n",
    "output_dropdown = widgets.Output()\n",
    "\n",
    "def on_change_dropdown(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        global chosed_musical_genre_scenario1\n",
    "        chosed_musical_genre_scenario1 = change['new']\n",
    "        \n",
    "w_dropdown.observe(on_change_dropdown)\n",
    "display(w_dropdown, output_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_int_slider = widgets.IntSlider(value=0, min=0, max=99, step=1,\n",
    "                                 description='File:', disabled=False,\n",
    "                                 continuous_update=False, orientation='horizontal',\n",
    "                                 readout=True, readout_format='d')\n",
    "\n",
    "output_int_slider = widgets.Output()\n",
    "\n",
    "def on_change_int_slider(change):\n",
    "    with output_int_slider:\n",
    "        global chosed_file_scenario1\n",
    "        chosed_file_scenario1 = change['new']\n",
    "        ipd.display(ipd.Javascript('IPython.notebook.execute_cells([37])'))\n",
    "        ipd.display(ipd.Javascript('IPython.notebook.execute_cells([38])'))\n",
    "w_int_slider.observe(on_change_int_slider, 'value')\n",
    "display(w_int_slider, output_int_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audios_dict[chosed_musical_genre_scenario1][0][chosed_file_scenario1], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_test = audios_dict[chosed_musical_genre_scenario1][0][chosed_file_scenario1]\n",
    "audio_test_mfcc = mfcc_feature_extract([audio_test], sr)[0]\n",
    "\n",
    "genre_dict = {0: 'popular', 1:'classico',\n",
    "              2:'jazz', 3:'rock'}\n",
    "\n",
    "predicted_musical_genre = genre_dict[model.predict([audio_test_mfcc])[0]]\n",
    "\n",
    "print('\\nA música inserida pertence ao estilo musical ' + '\\033[1m' + f'{predicted_musical_genre}' + '\\033[0;0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Cenário II\n",
    "\n",
    "* Usando 3 redes SVM:\n",
    "    * SVM1 - separa os estilos pop e classico dos estilos jazz e rock\n",
    "    * SVM2 - separa o estilo pop do estilo classico\n",
    "    * SVM3 - separa o estilo jazz do estilo rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_a_model(x, y, feature, features_params_dict):\n",
    "    \n",
    "    kernel = features_params_dict[f'{feature}']['kernel']\n",
    "    degree = features_params_dict[f'{feature}']['degree']\n",
    "    gamma = features_params_dict[f'{feature}']['gamma']\n",
    "    C = features_params_dict[f'{feature}']['C']\n",
    "    \n",
    "    model = svm.SVC(kernel=kernel, degree=degree, gamma=gamma, C=C)\n",
    "        \n",
    "    model.fit(x, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_scenario_score_and_models(train, test, features_params_dict, \n",
    "                                         feature_ex_svm1='lpc', feature_ex_svm23='mfcc'):\n",
    "    \n",
    "    # SVM1\n",
    "    model1 = training_a_model(train[f'{feature_ex_svm1}'].to_list(), \n",
    "                              train['y2'].to_list(),\n",
    "                              feature_ex_svm1, features_params_dict)\n",
    "    train['y2_predicted'] = model1.predict(train[f'{feature_ex_svm1}'].to_list())\n",
    "    \n",
    "    #SVM2\n",
    "    train_0 = train[train['y2_predicted']==0]\n",
    "    train_0 = train_0[train_0['y'].isin([0,1])]\n",
    "    \n",
    "    model2 = training_a_model(train_0[f'{feature_ex_svm23}'].to_list(), \n",
    "                              train_0['y'].to_list(),\n",
    "                              feature_ex_svm23, features_params_dict)\n",
    "    train_0['y_predicted'] = model2.predict(train_0[f'{feature_ex_svm23}'].to_list())\n",
    "    test_0 = test[test['y2']==0]\n",
    "    \n",
    "    #SVM3\n",
    "    train_1 = train[train['y2_predicted']==1]\n",
    "    train_1 = train_1[train_1['y'].isin([2,3])]\n",
    "    \n",
    "    model3 = training_a_model(train_1[f'{feature_ex_svm23}'].to_list(), \n",
    "                              train_1['y'].to_list(),\n",
    "                              feature_ex_svm23, features_params_dict)\n",
    "    train_1['y_predicted'] = model3.predict(train_1[f'{feature_ex_svm23}'].to_list())\n",
    "    test_1 = test[test['y2']==1]\n",
    "    \n",
    "    train_score = (\n",
    "        model2.score(train_0[f'{feature_ex_svm23}'].to_list(), train_0['y'].to_list()) * 0.5 +\n",
    "        model3.score(train_1[f'{feature_ex_svm23}'].to_list(), train_1['y'].to_list()) * 0.5\n",
    "    )\n",
    "    \n",
    "    test_score = (\n",
    "        model2.score(test_0[f'{feature_ex_svm23}'].to_list(), test_0['y'].to_list()) * 0.5 +\n",
    "        model3.score(test_1[f'{feature_ex_svm23}'].to_list(), test_1['y'].to_list()) * 0.5\n",
    "    )\n",
    "    \n",
    "    return model1, model2, model3, train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create own predict function\n",
    "def second_scenario_predict_an_audio(feature1, feature2, model1, model2, model3):    \n",
    "    y2_predicted = model1.predict(feature1)\n",
    "    \n",
    "    y_predicted_list = []\n",
    "    i=0\n",
    "    for predicted in y2_predicted:\n",
    "        \n",
    "        feature = feature2[i]\n",
    "        \n",
    "        if predicted == 0:\n",
    "            y_predicted = model2.predict([feature])\n",
    "        elif predicted == 1:\n",
    "            y_predicted = model3.predict([feature])\n",
    "            \n",
    "        y_predicted_list.append(y_predicted)\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    return y_predicted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 - Analisando cada extração de feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos analisar os resultados do cenário II alterando a extração de feature utilizada na SVM1 e nas SVM2 e SVM3 - vale ressaltar que a extração de feature utilizada na SVM2 é igual àquela utilizada na SVM3.\n",
    "\n",
    "Por simplificação, vamos apenas analisar as extrações LPC e MFCC e vamos utilizar os melhores parâmetros já encontrados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature1 in ['mfcc', 'lpc']:\n",
    "    for feature2 in ['mfcc', 'lpc']\n",
    "    \n",
    "        print(f'\\033[1m {features_without_abrev[feature1]} & {features_without_abrev[feature2]}:\\033[0;0m\\n')\n",
    "\n",
    "        model1, model2, model3, train_score, test_score = (\n",
    "                get_second_scenario_score_and_models(train, test, features_params_dict, \n",
    "                                                     feature_ex_svm1=feature1, feature_ex_svm23=feature2)\n",
    "        )\n",
    "\n",
    "        print('Train accuracy: {:.1%}'.format(train_score))\n",
    "        print('Test accuracy:  {:.1%}'.format(test_score))\n",
    "        print('\\n')\n",
    "\n",
    "        predictions = (\n",
    "            second_scenario_predict_an_audio(test[f'{feature1}'].to_list(), \n",
    "                                             test[f'{feature2}'].to_list(), \n",
    "                                             model1, model2, model3)\n",
    "        )\n",
    "        predictions = [x[0] for x in predictions]\n",
    "\n",
    "        plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(test['y'].to_list(), predictions),\n",
    "                                      display_labels=['pop', 'classical', 'jazz', 'rock'])\n",
    "        disp = disp.plot(include_values=True,\n",
    "                         cmap=plt.cm.BuPu)\n",
    "        disp.ax_.set_title(f'Confusion Matrix Using {features_without_abrev[feature1]} & {features_without_abrev[feature2]} (second scenario)', \n",
    "                           fontsize=16)\n",
    "\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 - Melhor Resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando o melhor resultado com base principalemente na porcentagem de acerto no dataset de teste, o melhor modelo foi o que utilizou kernel=poly e extração de feature MFCC nos 3 SVM utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, model2, model3, train_score, test_score = (\n",
    "    get_second_scenario_score_and_models(train, test, feature_ex_svm1='mfcc',\n",
    "                                         feature_ex_svm23='mfcc', degree=2)\n",
    ")\n",
    "\n",
    "predictions = (\n",
    "    second_scenario_predict_an_audio(test['mfcc'].to_list(), \n",
    "                                     test['mfcc'].to_list(), \n",
    "                                     model1, model2, model3)\n",
    ")\n",
    "predictions = [x[0] for x in predictions]\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(test['y'].to_list(), predictions),\n",
    "                              display_labels=['pop', 'classical', 'jazz', 'rock'])\n",
    "disp = disp.plot(include_values=True,\n",
    "                 cmap=plt.cm.BuPu)\n",
    "disp.ax_.set_title('Confusion Matrix Using MFCC & MFCC (second scenario)', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.show()\n",
    "\n",
    "print('\\033[1m' + 'Train accuracy:' + '\\033[0;0m' + ' {:.1%}'.format(train_score))\n",
    "print('\\033[1m' + 'Test accuracy: '+ '\\033[0;0m' + ' {:.1%}'.format(test_score))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 - Tentativa de predição com o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global chosed_musical_genre_scenario2\n",
    "chosed_musical_genre_scenario2 = 'pop'\n",
    "\n",
    "global chosed_file_scenario2\n",
    "chosed_file_scenario2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dropdown = widgets.Dropdown(options=['pop', 'classical', 'jazz', 'rock'],\n",
    "                              value='pop', description='Genero:', disabled=False)\n",
    "\n",
    "output_dropdown = widgets.Output()\n",
    "\n",
    "def on_change_dropdown(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        global chosed_musical_genre_scenario2\n",
    "        chosed_musical_genre_scenario2 = change['new']\n",
    "\n",
    "w_dropdown.observe(on_change_dropdown)\n",
    "display(w_dropdown, output_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_int_slider = widgets.IntSlider(value=0, min=0, max=99, step=1,\n",
    "                                 description='File:', disabled=False,\n",
    "                                 continuous_update=False, orientation='horizontal',\n",
    "                                 readout=True, readout_format='d')\n",
    "\n",
    "output_int_slider = widgets.Output()\n",
    "\n",
    "def on_change_int_slider(change):\n",
    "    with output_int_slider:\n",
    "        global chosed_file_scenario2\n",
    "        chosed_file_scenario2 = change['new']\n",
    "        ipd.display(ipd.Javascript('IPython.notebook.execute_cells([53])'))\n",
    "        ipd.display(ipd.Javascript('IPython.notebook.execute_cells([54])'))\n",
    "\n",
    "w_int_slider.observe(on_change_int_slider, 'value')\n",
    "display(w_int_slider, output_int_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audios_dict[chosed_musical_genre_scenario2][0][chosed_file_scenario2], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_test = audios_dict[chosed_musical_genre_scenario2][0][chosed_file_scenario2]\n",
    "audio_test_mfcc = mfcc_feature_extract([audio_test], sr)[0]\n",
    "\n",
    "genre_dict = {0: 'popular', 1:'classico',\n",
    "              2:'jazz', 3:'rock'}\n",
    "\n",
    "predicted_musical_genre = (\n",
    "    genre_dict[\n",
    "        second_scenario_predict_an_audio([audio_test_mfcc], [audio_test_mfcc], model1, model2, model3)[0][0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('\\nA música inserida pertence ao estilo musical ' + '\\033[1m' + f'{predicted_musical_genre}' + '\\033[0;0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Comparando os melhores resultados de cada cenário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cenário I\n",
    "model, train_score1, test_score1 = (\n",
    "    get_first_scenario_score_and_model(train, test, feature_ex='mfcc', \n",
    "                                       return_model=True, degree=2)\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "disp = plot_confusion_matrix(model, test['mfcc'].to_list(), \n",
    "                             test['y'].to_list(), labels=[0,1,2,3],\n",
    "                             display_labels=['pop', 'classical', 'jazz', 'rock'],\n",
    "                             cmap=plt.cm.BuPu)\n",
    "disp.ax_.set_title('Confusion Matrix Using MFCC (first scenario)', fontsize=16)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1m' + 'Train accuracy:' + '\\033[0;0m' + ' {:.1%}'.format(train_score1))\n",
    "print('\\033[1m' + 'Test accuracy: '+ '\\033[0;0m' + ' {:.1%}'.format(test_score1))\n",
    "print('\\n')\n",
    "\n",
    "# Cenário II\n",
    "model1, model2, model3, train_score2, test_score2 = (\n",
    "    get_second_scenario_score_and_models(train, test, feature_ex_svm1='mfcc',\n",
    "                                         feature_ex_svm23='mfcc', degree=2)\n",
    ")\n",
    "\n",
    "predictions = (\n",
    "    second_scenario_predict_an_audio(test['mfcc'].to_list(), \n",
    "                                     test['mfcc'].to_list(), \n",
    "                                     model1, model2, model3)\n",
    ")\n",
    "predictions = [x[0] for x in predictions]\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(test['y'].to_list(), predictions),\n",
    "                              display_labels=['pop', 'classical', 'jazz', 'rock'])\n",
    "disp = disp.plot(include_values=True,\n",
    "                 cmap=plt.cm.BuPu)\n",
    "disp.ax_.set_title('Confusion Matrix Using MFCC & MFCC (second scenario)', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.show()\n",
    "\n",
    "print('\\033[1m' + 'Train accuracy:' + '\\033[0;0m' + ' {:.1%}'.format(train_score2))\n",
    "print('\\033[1m' + 'Test accuracy: '+ '\\033[0;0m' + ' {:.1%}'.format(test_score2))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que, ao utilizar a separação inicial dos 4 estilos musicais em 2 grupos (cenário 2) a eficácia do modelo melhorou. Isso nos mostra que, tendo as mesmas ferramentas, podemos melhorar nosso modelo se conhecermos mais sobre o dataset utilizado - nesse caso, ao conhecer um pouco sobre teoria da música, percebemos que seria mais fácil separar, por exemplo, o estilo popular do estilo clássico do que o estilo jazz do estilo classico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
